{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-03T05:50:55.355252Z",
     "start_time": "2025-11-03T05:50:55.340599Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T05:50:55.831592Z",
     "start_time": "2025-11-03T05:50:55.364453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#reads spike duration databse (aka table with spike start and end times)\n",
    "df = pd.read_excel(\"/Users/csengi/Documents/CsengeR-CA3PC/duration_database.xlsx\")  # or read_csv\n",
    "\n",
    "cell_name_list      = df[\"cell_name\"].tolist()\n",
    "file_name_list      = df[\"full_file_name\"].tolist()\n",
    "drug_list           = df[\"drug\"].tolist()\n",
    "stim_list           = df[\"stim\"].tolist()\n",
    "parameter_list      = df[\"parameter\"].tolist()\n",
    "spike_start_list    = df[\"spike_start\"].tolist()\n",
    "spike_end_list      = df[\"spike_end\"].tolist()\n",
    "exclude_list        = df[\"exclude?\"].tolist()\n"
   ],
   "id": "c1635d8cc6aa7c26",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T05:50:55.840085Z",
     "start_time": "2025-11-03T05:50:55.837102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_row(row_number):\n",
    "    row = df.iloc[row_number]\n",
    "    print(row.to_string())"
   ],
   "id": "250494e0294c3eb5",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T05:50:55.852243Z",
     "start_time": "2025-11-03T05:50:55.847830Z"
    }
   },
   "cell_type": "code",
   "source": "print_row(2)",
   "id": "bf660f47a0b3987",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell_name                                    KN190320c1\n",
      "full_file_name    KN190320c1-TTAP2-V_008_tf_800_042.txt\n",
      "drug                                              TTAP2\n",
      "stim                                               1sec\n",
      "parameter                              V_008_tf_800_042\n",
      "spike_start                                     0.25002\n",
      "spike_end                                       0.34706\n",
      "exclude?                                            NaN\n"
     ]
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T05:50:55.887289Z",
     "start_time": "2025-11-03T05:50:55.872675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataSet:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "        #alphabetically! IMPORTANT!\n",
    "        self.files = sorted([f for f in os.listdir(path) if not f.startswith('.')])\n",
    "        self.get_cell_list()\n",
    "\n",
    "    def get_cell_list(self):\n",
    "        self.fname_cell_txt = []\n",
    "        self.fname_drug_txt = []\n",
    "        self.fname_stim_txt = []\n",
    "        self.fname_params_txt = []\n",
    "        self.fname_num_txt = []\n",
    "\n",
    "        for i in range(len(self.files)):\n",
    "            file = self.files[i]\n",
    "            snips = file.split('-')\n",
    "\n",
    "            self.fname_cell_txt.append(snips[0])\n",
    "            self.fname_drug_txt.append(snips[1])\n",
    "\n",
    "            if len(snips) == 3:\n",
    "                self.fname_stim_txt.append('1sec')\n",
    "                param_name = snips[2].replace('.txt', '')\n",
    "            elif len(snips) == 4:\n",
    "                self.fname_stim_txt.append(snips[2])\n",
    "                param_name = snips[3].replace('.txt', '')\n",
    "\n",
    "            parts = param_name.split('_')\n",
    "            if parts[-1].isdigit():\n",
    "                self.fname_num_txt.append(parts[-1])\n",
    "                param_name = '_'.join(parts[:-1])\n",
    "            else:\n",
    "                self.fname_num_txt.append(None)\n",
    "            self.fname_params_txt.append(param_name)\n",
    "\n",
    "        self.fname_cell_txt = np.array(self.fname_cell_txt)\n",
    "        self.fname_drug_txt = np.array(self.fname_drug_txt)\n",
    "        self.fname_stim_txt = np.array(self.fname_stim_txt)\n",
    "        self.fname_params_txt = np.array(self.fname_params_txt)\n",
    "        self.fname_num_txt = np.array(self.fname_num_txt)\n",
    "\n",
    "        self.cells_names = np.unique(self.fname_cell_txt)\n",
    "        self.drugs = np.unique(self.fname_drug_txt)"
   ],
   "id": "60f8887134f472e7",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T05:50:55.923962Z",
     "start_time": "2025-11-03T05:50:55.893974Z"
    }
   },
   "cell_type": "code",
   "source": "A1 = DataSet('/Users/csengi/Documents/CsengeR-CA3PC/CaSpikes/txt_traces_fixed')",
   "id": "e65cc47f2d85e5e2",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T05:50:55.935922Z",
     "start_time": "2025-11-03T05:50:55.932684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for f in A1.files[:10]:\n",
    "    print(f)"
   ],
   "id": "95bac9e9f84681ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00KN190329c1-TTX1-V_011_tf_700_021.txt\n",
      "KN190320c1-TTAP2-V_008_tf_800_041.txt\n",
      "KN190320c1-TTAP2-V_008_tf_800_042.txt\n",
      "KN190320c1-TTAP2-V_008_tf_800_043.txt\n",
      "KN190320c1-TTAP2-V_008_tf_800_044.txt\n",
      "KN190320c1-TTAP2-V_008_tf_800_045.txt\n",
      "KN190320c1-TTX1-V_007_tf_500_011.txt\n",
      "KN190320c1-TTX1-V_007_tf_500_014.txt\n",
      "KN190320c1-TTX1-V_007_tf_500_015.txt\n",
      "KN190320c1-TTX1-V_007_tf_500_016.txt\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T05:50:55.950966Z",
     "start_time": "2025-11-03T05:50:55.948527Z"
    }
   },
   "cell_type": "code",
   "source": "print(A1.files[2]) #(element 2 corresponds to the 2 in the loaded table lists)",
   "id": "2da4b600efb771c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KN190320c1-TTAP2-V_008_tf_800_042.txt\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T05:50:55.969640Z",
     "start_time": "2025-11-03T05:50:55.964232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def SmoothTraces(traces, delta_t, sd):\n",
    "    out = np.zeros(traces.shape)\n",
    "    for i in range(traces.shape[0]):\n",
    "        ROI = np.copy(traces[i,:])\n",
    "        out[i,:] = gaussian_filter(ROI, delta_t, sd)\n",
    "    return out\n",
    "\n",
    "def gaussian_filter(trace, delta_t =2e-5, sdfilt = 0.00135, N =10):\n",
    "    sd = sdfilt/delta_t\n",
    "    N = 10\n",
    "    sampling_time = 1\n",
    "\n",
    "    if int(N*sd) == 0:\n",
    "        return trace\n",
    "\n",
    "    xfilt = np.arange(int(-N*sd), int(N*sd) + sampling_time, sampling_time)\n",
    "    filt = np.exp(-(xfilt**2) / (2*(sd**2)))\n",
    "    filt = filt/sum(filt)\n",
    "\n",
    "    temp = np.hstack([np.repeat(trace[0], N*sd),trace, np.repeat(trace[-1], N*sd)])\n",
    "    result = np.convolve(temp, filt, mode = 'valid')\n",
    "\n",
    "    return result"
   ],
   "id": "687e1720322cf3a8",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T05:50:56.110176Z",
     "start_time": "2025-11-03T05:50:56.094828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SingleTrace:\n",
    "    def __init__(self, pre_data, trace_index):\n",
    "        self.spike_start_time = df.iloc[trace_index][\"spike_start\"]\n",
    "        self.spike_end_time = df.iloc[trace_index][\"spike_end\"]\n",
    "        mask = (pre_data[:, 0] >= self.spike_start_time-0.001) & (pre_data[:, 0] <= self.spike_end_time+0.001)\n",
    "        data = pre_data[mask]\n",
    "        self.times = data[:, 0]\n",
    "        self.voltages = data[:, 1]\n",
    "\n",
    "        try:\n",
    "            self.calculate_dVdt(self.times, self.voltages)\n",
    "            self.calculate_threshold(prominence=250)\n",
    "            # for prominence in range(250, 0, -25):  # tries 350 -> 50 prominences\n",
    "            #     try:\n",
    "            #         dVdt_peaks, _ = find_peaks(self.dVdt, prominence=prominence)\n",
    "            #         if len(dVdt_peaks) >= 1:\n",
    "            #             self.calculate_threshold(prominence)\n",
    "            #     except Exception:\n",
    "            #         continue\n",
    "            self.calculate_V_peaks()\n",
    "            self.calculate_amplitude()\n",
    "            self.calculate_halfwidth()\n",
    "            self.calculate_area_under_spike()\n",
    "            self.calculate_injection_to_threshold()\n",
    "            self.calculate_interpeak_adaptation_index()\n",
    "            self.calculate_repolarization_check()\n",
    "        except Exception as e:\n",
    "            print(f\" An error occured during data extraction: {str(e)}\")\n",
    "\n",
    "    def calculate_dVdt(self, times, voltages):\n",
    "        self.dVdt = np.diff(voltages) / np.diff(times)\n",
    "        self.dVdt_max = np.max(self.dVdt)\n",
    "        self.dVdt_min = np.min(self.dVdt)\n",
    "        self.dVdt_total = self.dVdt_max - self.dVdt_min\n",
    "        self.dVdt_max_time = times[1:][np.argmax(self.dVdt)]\n",
    "        self.dVdt_min_time = times[1:][np.argmin(self.dVdt)]\n",
    "\n",
    "    def calculate_threshold(self, prominence):\n",
    "        dVdt_peaks, _ = find_peaks(self.dVdt, prominence=prominence)\n",
    "\n",
    "        first_peak_index = dVdt_peaks[0]\n",
    "        first_peak_value = self.dVdt[first_peak_index]\n",
    "        self.first_dVdt_peak_time = self.times[1:][first_peak_index]\n",
    "\n",
    "        dVdt_threshold = min(0.2 * first_peak_value, 250)\n",
    "\n",
    "        threshold_index = None\n",
    "        for i in range(first_peak_index, 1, -1):\n",
    "            if self.dVdt[i - 1] <= dVdt_threshold <= self.dVdt[i]:\n",
    "                threshold_index = i\n",
    "                break\n",
    "        if threshold_index is None:\n",
    "            threshold_index = 0\n",
    "\n",
    "        self.threshold_index = threshold_index\n",
    "        self.threshold_time = self.times[1:][threshold_index]\n",
    "        self.threshold = self.voltages[1:][threshold_index]\n",
    "\n",
    "    def calculate_amplitude(self):\n",
    "        self.max_voltage = np.max(self.voltages)\n",
    "        self.amplitude = self.max_voltage - self.threshold\n",
    "\n",
    "    def calculate_halfwidth(self):\n",
    "\n",
    "        half_voltage = self.threshold + 0.5 * self.amplitude\n",
    "        self.above_half = np.where(self.voltages >= half_voltage)[0]\n",
    "\n",
    "        t_rise = self.times[self.above_half[0]]\n",
    "        t_fall = self.times[self.above_half[-1]]\n",
    "\n",
    "        self.halfwidth = t_fall - t_rise\n",
    "\n",
    "    def calculate_V_peaks(self, prominence=2):\n",
    "        self.V_peak_indices, _ = find_peaks(self.voltages, prominence=prominence)\n",
    "        self.number_of_V_peaks = len(self.V_peak_indices)\n",
    "        if self.number_of_V_peaks > 0:\n",
    "            self.V_first_peak_time = self.times[self.V_peak_indices[0]]\n",
    "        else:\n",
    "            self.V_first_peak_time = np.nan\n",
    "\n",
    "    def calculate_area_under_spike(self):\n",
    "        above_threshold = self.voltages > self.threshold\n",
    "        voltages_above = np.where(above_threshold, self.voltages - self.threshold, 0)\n",
    "        self.area = np.trapezoid(voltages_above, self.times)\n",
    "\n",
    "    def calculate_injection_to_threshold(self, injection_start=0.25):\n",
    "        self.injection_start = injection_start\n",
    "        self.injection_to_threshold_time = self.threshold_time - injection_start\n",
    "\n",
    "    def calculate_interpeak_adaptation_index(self):\n",
    "        if len(self.V_peak_indices) > 2:\n",
    "            self.interpeak_intervals = np.diff(self.times[self.V_peak_indices])\n",
    "            self.adaptation_index = self.interpeak_intervals[-1] / self.interpeak_intervals[0]\n",
    "        else:\n",
    "            self.adaptation_index = np.nan\n",
    "\n",
    "    def calculate_repolarization_check(self, min_time_for_check=1.2):\n",
    "\n",
    "        self.final_voltage = self.voltages[-1]\n",
    "        start_voltage = self.voltages[0]\n",
    "        stop_voltage = self.voltages[-1]\n",
    "        last_time = self.times[-1]\n",
    "\n",
    "        if last_time < min_time_for_check:\n",
    "            self.sustained = False\n",
    "            self.amplitude_final_difference = np.nan\n",
    "            self.amplitude_final_ratio = np.nan\n",
    "            return\n",
    "\n",
    "        if np.isclose(stop_voltage, start_voltage, atol=1):\n",
    "            self.sustained = False\n",
    "            self.amplitude_final_difference = np.nan\n",
    "            self.amplitude_final_ratio = np.nan\n",
    "        else:\n",
    "            self.sustained = True\n",
    "            self.amplitude_final_difference = self.amplitude - self.final_voltage\n",
    "            self.amplitude_final_ratio = (\n",
    "                abs(self.final_voltage / self.amplitude_final_difference)\n",
    "                if self.amplitude_final_difference != 0 else np.nan\n",
    "            )"
   ],
   "id": "4f09f6eabdb03638",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T05:50:56.145746Z",
     "start_time": "2025-11-03T05:50:56.125636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Cell:\n",
    "    def __init__(self, cell, path, all_cells):\n",
    "        if cell in all_cells:\n",
    "            self.cell = cell\n",
    "            self.load_path = path\n",
    "            self.save_path = path + '/saved_data/' + cell\n",
    "            self.global_path = path\n",
    "            self.all_cells = all_cells\n",
    "            self.frame_rate = 50000\n",
    "            self.dt = 0.00002\n",
    "\n",
    "            self.files = []\n",
    "            self.drugs = []\n",
    "            self.stim = []\n",
    "            self.params = []\n",
    "            self.nums = []\n",
    "\n",
    "            self.traces_dict = {}\n",
    "            self.steps_dict = {}\n",
    "            self.stim_dict = {}\n",
    "\n",
    "            self.get_filewise_properties()\n",
    "            self.build_dictionaries()\n",
    "            self.calculate_parameters()\n",
    "\n",
    "        else:\n",
    "            print('cell ID is not valid!')\n",
    "            return\n",
    "\n",
    "    def get_filewise_properties(self):\n",
    "        files = os.listdir(path=self.load_path)\n",
    "\n",
    "        self.files = []\n",
    "        self.drugs = []\n",
    "        self.stim = []\n",
    "        self.params = []\n",
    "        self.nums = []\n",
    "\n",
    "        for file in files:\n",
    "            snips = file.split('-')\n",
    "            if snips[0] == self.cell:\n",
    "                self.files.append(self.load_path + '/' + file)\n",
    "                self.drugs.append(snips[1])\n",
    "\n",
    "                param_name = snips[-1].replace('.txt', '')\n",
    "                parts = param_name.split('_')\n",
    "\n",
    "                if parts[-1].isdigit():\n",
    "                    self.nums.append(parts[-1])\n",
    "                    param_name = '_'.join(parts[:-1])\n",
    "                else:\n",
    "                    self.nums.append(None)\n",
    "                    param_name = '_'.join(parts)\n",
    "\n",
    "                self.params.append(param_name)\n",
    "\n",
    "                if len(snips) == 4:\n",
    "                    self.stim.append(snips[2])\n",
    "                else:\n",
    "                    self.stim.append('1sec')\n",
    "\n",
    "        self.N = len(self.files)\n",
    "        self.drugs = np.array(self.drugs)\n",
    "        self.files = np.array(self.files)\n",
    "        self.stim = np.array(self.stim)\n",
    "        self.params = np.array(self.params)\n",
    "        self.nums = np.array(self.nums)\n",
    "\n",
    "    def build_dictionaries(self):\n",
    "        traces = []\n",
    "        for i in range(self.N):\n",
    "            f = open(self.files[i], 'r')\n",
    "            f.readline()\n",
    "            data = []\n",
    "            for line in f:\n",
    "                [x, y] = line.split('\\t')\n",
    "                data.append(float(y))\n",
    "            traces.append(np.array(data))\n",
    "        traces = np.array(traces)\n",
    "        if np.ndim(traces) != 2:\n",
    "            print('Error! wave length is not uniform!')\n",
    "            return\n",
    "\n",
    "        drugs = np.unique(self.drugs)\n",
    "        trace_values = []\n",
    "        stim_values = []\n",
    "\n",
    "        for i_drug in range(len(drugs)):\n",
    "            drug_indexes = np.where(self.drugs == drugs[i_drug])[0]\n",
    "            trace_values.append(traces[drug_indexes, :])\n",
    "            stim_values.append(self.stim[drug_indexes])\n",
    "\n",
    "        for i in range(len(drugs)):\n",
    "            self.traces_dict[drugs[i]] = trace_values[i]\n",
    "            self.stim_dict[drugs[i]] = stim_values[i]\n",
    "\n",
    "    def calculate_parameters(self):\n",
    "        parameter_table_by_condition = {}\n",
    "\n",
    "        # names of parameters that will be averaged normally\n",
    "        param_names = [\n",
    "            'dVdt_total', 'dVdt_max', 'dVdt_min', 'amplitude', 'halfwidth',\n",
    "            'threshold', 'number of peaks',\n",
    "            'inj -> thr (t)', 'area'\n",
    "        ]\n",
    "\n",
    "        unique_drugs = np.unique(self.drugs)\n",
    "\n",
    "        for drug in unique_drugs:\n",
    "            condition_indices = np.where(self.drugs == drug)[0]\n",
    "\n",
    "            parameter_table = []                  # numeric parameters to average\n",
    "            adaptation_index_list = []            # special: not simply averaged blindly\n",
    "            sustained_list = []                   # True only if all traces true\n",
    "            amp_final_diff_list = []              # repolarization metric\n",
    "            amp_final_ratio_list = []             # repolarization metric\n",
    "\n",
    "            for idx in condition_indices:\n",
    "\n",
    "                # skip traces excluded in excel\n",
    "                if df.iloc[idx][\"exclude?\"] == \"YES\":\n",
    "                    continue\n",
    "\n",
    "                txt_name = os.path.basename(self.files[idx]).replace(\".txt\", \"\")\n",
    "                df_names = df[\"full_file_name\"].astype(str).apply(\n",
    "                    lambda x: os.path.basename(x).replace(\".txt\", \"\")\n",
    "                )\n",
    "                matching_rows = df_names[df_names == txt_name]\n",
    "\n",
    "                if matching_rows.empty:\n",
    "                    print(f\"No Excel entry found for: {txt_name}\")\n",
    "                    continue\n",
    "\n",
    "                trace_index = matching_rows.index[0]\n",
    "\n",
    "                # load trace (+ filtering)\n",
    "                data = np.loadtxt(self.files[idx], delimiter='\\t', skiprows=1)\n",
    "                time = data[:, 0]\n",
    "                voltage = gaussian_filter(data[:, 1])\n",
    "                pre_data = np.column_stack([time, voltage])\n",
    "\n",
    "                # Extract all spike parameters\n",
    "                calculated_cell = SingleTrace(pre_data, trace_index=trace_index)\n",
    "\n",
    "                # store standard parameters\n",
    "                parameters = [\n",
    "                    calculated_cell.dVdt_total,\n",
    "                    calculated_cell.dVdt_max,\n",
    "                    calculated_cell.dVdt_min,\n",
    "                    calculated_cell.amplitude,\n",
    "                    calculated_cell.halfwidth,\n",
    "                    calculated_cell.threshold,\n",
    "                    calculated_cell.number_of_V_peaks,\n",
    "                    calculated_cell.injection_to_threshold_time,\n",
    "                    calculated_cell.area\n",
    "                ]\n",
    "                parameter_table.append(parameters)\n",
    "\n",
    "                # store special parameters\n",
    "                adaptation_index_list.append(calculated_cell.adaptation_index)\n",
    "                sustained_list.append(calculated_cell.sustained)\n",
    "                amp_final_diff_list.append(calculated_cell.amplitude_final_difference)\n",
    "                amp_final_ratio_list.append(calculated_cell.amplitude_final_ratio)\n",
    "\n",
    "            if len(parameter_table) == 0:\n",
    "                # nothing valid, assign NaN row\n",
    "                parameter_table_by_condition[(drug, None, None)] = {name: np.nan for name in param_names}\n",
    "                continue\n",
    "\n",
    "            # ---- AGGREGATION SECTION ----\n",
    "\n",
    "            # mean of standard numeric parameters\n",
    "            mean_values = np.nanmean(np.vstack(parameter_table), axis=0)\n",
    "            clean_values = [float(x) if not np.isnan(x) else np.nan for x in mean_values]\n",
    "\n",
    "            # Adaptation index\n",
    "            if np.any(~np.isnan(adaptation_index_list)):\n",
    "                adaptation_index_value = float(np.nanmean(adaptation_index_list))\n",
    "            else:\n",
    "                adaptation_index_value = np.nan\n",
    "\n",
    "            # sustained = True only if ALL are true\n",
    "            sustained_value = all(sustained_list)\n",
    "\n",
    "            # repolarization metrics (avoid warnings by checking NaN presence)\n",
    "            if np.any(~np.isnan(amp_final_diff_list)):\n",
    "                final_diff_value = float(np.nanmedian(amp_final_diff_list))\n",
    "            else:\n",
    "                final_diff_value = np.nan\n",
    "\n",
    "            if np.any(~np.isnan(amp_final_ratio_list)):\n",
    "                final_ratio_value = float(np.nanmedian(amp_final_ratio_list))\n",
    "            else:\n",
    "                final_ratio_value = np.nan\n",
    "\n",
    "            # save to dictionary, preserving the stim + param info\n",
    "            # (use the *first* member of the condition group for indexing)\n",
    "            stim = self.stim[condition_indices][0]\n",
    "            param = self.params[condition_indices][0]\n",
    "\n",
    "            parameter_table_by_condition[(drug, stim, param)] = {\n",
    "                'dVdt_total': clean_values[0],\n",
    "                'dVdt_max': clean_values[1],\n",
    "                'dVdt_min': clean_values[2],\n",
    "                'amplitude': clean_values[3],\n",
    "                'halfwidth': clean_values[4],\n",
    "                'threshold': clean_values[5],\n",
    "                'number of peaks': clean_values[6],\n",
    "                'inj -> thr (t)': clean_values[7],\n",
    "                'area': clean_values[8],\n",
    "                'adaptation_index': adaptation_index_value,\n",
    "                'sustained': sustained_value,\n",
    "                'amp. difference': final_diff_value,\n",
    "                'amp. ratio': final_ratio_value\n",
    "            }\n",
    "\n",
    "        self.parameters_by_condition = parameter_table_by_condition\n",
    "\n"
   ],
   "id": "5e4f4ff4c3568a7a",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T05:56:22.247857Z",
     "start_time": "2025-11-03T05:50:56.151822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_results = []\n",
    "param_names = [\n",
    "    'dVdt_total', 'dVdt_max', 'dVdt_min', 'amplitude', 'halfwidth',\n",
    "    'threshold', 'number of peaks', 'inj -> thr (t)', 'area',\n",
    "    'adaptation_index', 'sustained', 'amp. difference', 'amp. ratio'\n",
    "]\n",
    "\n",
    "\n",
    "for cell_name in tqdm(A1.cells_names, desc=\"Processing cells\", unit=\"cell\"):\n",
    "    try:\n",
    "        d0 = Cell(cell_name, A1.path, A1.cells_names)\n",
    "\n",
    "        for condition, params in d0.parameters_by_condition.items():\n",
    "            drug, stim, param = condition\n",
    "\n",
    "            row = {'cell': cell_name, 'drug': drug, 'stim': stim, 'param': param}\n",
    "            for name in param_names:\n",
    "                row[name] = params.get(name, np.nan)\n",
    "\n",
    "            all_results.append(row)\n",
    "\n",
    "    except Exception as e_outer:\n",
    "        tqdm.write(f\"Skipping {cell_name} due to major error: {e_outer}\")\n",
    "        row = {'cell': cell_name, 'drug': np.nan, 'stim': np.nan, 'param': np.nan}\n",
    "        for name in param_names:\n",
    "            row[name] = np.nan\n",
    "        all_results.append(row)\n",
    "\n",
    "df2 = pd.DataFrame(all_results)\n",
    "\n",
    "cols = ['cell', 'drug', 'stim', 'param'] + param_names\n",
    "df2 = df2[cols]\n",
    "\n",
    "save_dir = '/Users/csengi/Documents/CsengeR-CA3PC'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "save_path = os.path.join(save_dir, 'summary_parameters.csv')\n",
    "\n",
    "df2.to_csv(save_path, index=False)\n",
    "\n",
    "print(\"\\nSummary table saved to:\", save_path)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df2.head())\n"
   ],
   "id": "de11c5ffbf303d03",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cells:   5%|▍         | 16/337 [00:14<04:34,  1.17cell/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An error occured during data extraction: index 0 is out of bounds for axis 0 with size 0\n",
      "Skipping KN190625c1 due to major error: 'SingleTrace' object has no attribute 'amplitude'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cells:  13%|█▎        | 43/337 [00:42<04:19,  1.13cell/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An error occured during data extraction: index 0 is out of bounds for axis 0 with size 0\n",
      "Skipping KN191008c1 due to major error: 'SingleTrace' object has no attribute 'amplitude'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cells:  16%|█▌        | 53/337 [00:51<04:26,  1.07cell/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An error occured during data extraction: index 0 is out of bounds for axis 0 with size 0\n",
      "Skipping KN191104c2 due to major error: 'SingleTrace' object has no attribute 'amplitude'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cells:  21%|██▏       | 72/337 [01:08<03:38,  1.21cell/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An error occured during data extraction: index 0 is out of bounds for axis 0 with size 0\n",
      "Skipping KN200218c1 due to major error: 'SingleTrace' object has no attribute 'amplitude'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cells:  27%|██▋       | 90/337 [01:28<04:40,  1.14s/cell]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An error occured during data extraction: index 0 is out of bounds for axis 0 with size 0\n",
      "Skipping KN200729c2 due to major error: 'SingleTrace' object has no attribute 'amplitude'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cells:  27%|██▋       | 91/337 [01:29<04:20,  1.06s/cell]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An error occured during data extraction: index 0 is out of bounds for axis 0 with size 0\n",
      "Skipping KN200729c3 due to major error: 'SingleTrace' object has no attribute 'amplitude'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cells:  27%|██▋       | 92/337 [01:29<03:59,  1.02cell/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An error occured during data extraction: index 0 is out of bounds for axis 0 with size 0\n",
      "Skipping KN200810c2 due to major error: 'SingleTrace' object has no attribute 'amplitude'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cells:  62%|██████▏   | 210/337 [03:37<02:10,  1.03s/cell]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An error occured during data extraction: index 0 is out of bounds for axis 0 with size 0\n",
      "Skipping KN221003c1 due to major error: 'SingleTrace' object has no attribute 'amplitude'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cells:  63%|██████▎   | 211/337 [03:38<01:50,  1.14cell/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An error occured during data extraction: index 0 is out of bounds for axis 0 with size 0\n",
      "Skipping KN221004c1 due to major error: 'SingleTrace' object has no attribute 'amplitude'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cells:  63%|██████▎   | 213/337 [03:39<01:37,  1.27cell/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An error occured during data extraction: index 0 is out of bounds for axis 0 with size 0\n",
      "Skipping KN221109c1 due to major error: 'SingleTrace' object has no attribute 'amplitude'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cells:  66%|██████▋   | 224/337 [03:52<01:32,  1.22cell/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An error occured during data extraction: index 0 is out of bounds for axis 0 with size 0\n",
      "Skipping KN230215c2 due to major error: 'SingleTrace' object has no attribute 'amplitude'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cells:  69%|██████▉   | 234/337 [04:00<01:20,  1.28cell/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An error occured during data extraction: index 0 is out of bounds for axis 0 with size 0\n",
      "Skipping KN230314c1 due to major error: 'SingleTrace' object has no attribute 'amplitude'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cells:  94%|█████████▍| 318/337 [05:11<00:11,  1.70cell/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " An error occured during data extraction: index 0 is out of bounds for axis 0 with size 0\n",
      "Skipping SA181002 due to major error: 'SingleTrace' object has no attribute 'amplitude'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing cells: 100%|██████████| 337/337 [05:26<00:00,  1.03cell/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary table saved to: /Users/csengi/Documents/CsengeR-CA3PC/summary_parameters.csv\n",
      "\n",
      "First few rows:\n",
      "           cell   drug  stim         param   dVdt_total     dVdt_max  \\\n",
      "0  00KN190329c1   TTX1  1sec  V_011_tf_700  3986.417972  1326.058220   \n",
      "1    KN190320c1  TTAP2  1sec  V_008_tf_800   772.750640   349.322277   \n",
      "2    KN190320c1   TTX1  1sec  V_007_tf_500  2339.996482   823.756296   \n",
      "3    KN190329c1    SNX  1sec  V_013_tf_800  4038.003330  1062.126440   \n",
      "4    KN190329c1   TTX1  1sec  V_011_tf_700  4031.773945  1474.402448   \n",
      "\n",
      "      dVdt_min  amplitude  halfwidth  threshold  number of peaks  \\\n",
      "0 -2660.359752  14.504503   0.112440 -24.022232              4.0   \n",
      "1  -423.428362   9.614397   0.056612 -30.256966              1.0   \n",
      "2 -1516.240186   9.923786   0.047912 -28.604749              2.6   \n",
      "3 -2975.876890  11.590983   0.116384 -23.053626              4.2   \n",
      "4 -2557.371497  13.831961   0.104656 -23.215943              4.6   \n",
      "\n",
      "   inj -> thr (t)      area  adaptation_index sustained  amp. difference  \\\n",
      "0        0.503620  1.807752          1.212230      True        43.043041   \n",
      "1        0.016272  0.561955               NaN     False              NaN   \n",
      "2        0.171852  0.412607          1.583237     False              NaN   \n",
      "3        0.504996  1.055705          2.515824      True        40.334915   \n",
      "4        0.475628  1.409282          5.418433     False        41.014708   \n",
      "\n",
      "   amp. ratio  \n",
      "0    0.663023  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3    0.705910  \n",
      "4    0.658727  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 96
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
